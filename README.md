# Realtime AI Backend

A high-performance, asynchronous Python backend for real-time conversational AI sessions using WebSockets, Supabase, and OpenAI GPT-4o-mini.

---

## ğŸš€ Features

| Feature | Description |
|---------|-------------|
| **Real-time Streaming** | Token-by-token AI responses via WebSocket for low-latency UX |
| **AI Integration** | OpenAI GPT-4o-mini with intelligent context management |
| **Tool/Function Calling** | Server-side tool execution (e.g., shipping calculator) |
| **Persistent Storage** | Full session & event logging to Supabase Postgres |
| **Auto-Summarization** | LLM-generated session summaries on disconnect |
| **Markdown Rendering** | Frontend renders AI responses with proper formatting |

---

## ğŸ“ Project Structure

```
Realtime AI Backend/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # FastAPI server & WebSocket endpoints
â”‚   â”œâ”€â”€ llm.py           # OpenAI integration & streaming logic
â”‚   â””â”€â”€ database.py      # Supabase database operations
â”œâ”€â”€ client/
â”‚   â””â”€â”€ index.html       # Frontend chat interface
â”œâ”€â”€ .env                 # API keys (not committed - see .gitignore)
â”œâ”€â”€ .gitignore           # Git ignore rules
â”œâ”€â”€ requirements.txt     # Python dependencies
â”œâ”€â”€ setup_db.sql         # Supabase database schema
â””â”€â”€ README.md            # This file
```

---

## ğŸ› ï¸ Prerequisites

- **Python 3.9+**
- **Supabase** account with a project ([supabase.com](https://supabase.com/))
- **OpenAI** API key ([platform.openai.com](https://platform.openai.com/))

---

## âš™ï¸ Setup & Installation

### 1. Clone the Project
```bash
git clone <repository-url>
cd "Realtime AI Backend"
```

### 2. Create Virtual Environment
```bash
# Windows
python -m venv env
.\env\Scripts\activate

# Mac/Linux
python3 -m venv env
source env/bin/activate
```

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Configure Environment Variables
Create a `.env` file in the root directory:
```env
SUPABASE_URL=your_supabase_project_url
SUPABASE_KEY=your_supabase_service_role_key
OPENAI_API_KEY=your_openai_api_key
```

### 5. Setup Database
Run the contents of `setup_db.sql` in your **Supabase SQL Editor**:

```sql
-- Create sessions table
CREATE TABLE sessions (
  session_id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
  user_id TEXT NOT NULL,
  start_time TIMESTAMP WITH TIME ZONE DEFAULT NOW(),
  end_time TIMESTAMP WITH TIME ZONE,
  summary TEXT
);

-- Create session_events table
CREATE TABLE session_events (
  id BIGINT GENERATED BY DEFAULT AS IDENTITY PRIMARY KEY,
  session_id UUID REFERENCES sessions(session_id) ON DELETE CASCADE NOT NULL,
  event_type TEXT NOT NULL,
  content TEXT,
  metadata JSONB,
  created_at TIMESTAMP WITH TIME ZONE DEFAULT NOW()
);

-- Enable Row Level Security
ALTER TABLE sessions ENABLE ROW LEVEL SECURITY;
ALTER TABLE session_events ENABLE ROW LEVEL SECURITY;

-- Refresh schema cache
NOTIFY pgrst, 'reload schema';
```

---

## â–¶ï¸ Running the Application

Start the FastAPI server:
```bash
uvicorn app.main:app --reload
```

The server runs at: **http://127.0.0.1:8000**

---

## ğŸ§ª Usage & Testing

### 1. Open the Chat Interface
Navigate to [http://localhost:8000](http://localhost:8000)

### 2. Connect
- Enter a **User ID** (e.g., "Pavithra")
- Click **Connect** (status dot turns green)

### 3. Chat with AI
Try these examples:
- `"Hello, I'm [Your Name]"` â€” Tests greeting & context
- `"What is 10 + 2?"` â€” Tests simple Q&A
- `"How much to ship 5kg to the US?"` â€” Tests tool calling
- `"What is my name?"` â€” Tests conversation memory

### 4. Verify in Supabase
- **Table Editor â†’ sessions**: See active/closed sessions
- **Table Editor â†’ session_events**: See all messages & tool calls

### 5. Test Summarization
- Click **Disconnect**
- Check `sessions` table â€” `summary` and `end_time` columns will be populated

---

## ğŸ—ï¸ Architecture & Design Decisions

### Why FastAPI?
- Native async/await support for WebSockets
- High concurrency with minimal overhead
- Automatic OpenAPI documentation

### Why Granular Event Logging?
Instead of storing conversations as JSON blobs, we log individual events:
- **Replayability**: Reconstruct exact conversation timeline
- **Analytics**: Query tool usage patterns, response times
- **Debugging**: Trace issues to specific events

### Why Server-Side Tool Management?
- Frontend remains "dumb" â€” only sends/receives text
- Business logic and API keys stay secure on server
- Easier to add new tools without frontend changes

### Why Background Summarization?
- LLM summarization adds latency
- Triggered as background task after disconnect
- User experience remains responsive

---

## ğŸ“‹ API Reference

### WebSocket Endpoint
```
WS /ws/session/{session_id}?user_id={user_id}
```

### Message Protocol (JSON)

**Server â†’ Client:**
```json
{"type": "content", "value": "token text"}     // Streaming token
{"type": "tool_start", "tool": "tool_name"}    // Tool execution started
{"type": "tool_end", "tool": "tool_name"}      // Tool execution completed
```

**Client â†’ Server:**
```
Plain text message
```

---

## ğŸ”§ Technologies Used

| Technology | Purpose |
|------------|---------|
| FastAPI | Async web framework |
| Uvicorn | ASGI server |
| WebSockets | Real-time bidirectional communication |
| OpenAI API | GPT-4o-mini for AI responses |
| Supabase | PostgreSQL database & authentication |
| Python 3.9+ | Backend language |

---


